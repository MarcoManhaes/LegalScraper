# LegalScraper
Reposit√≥rio destinado √† prova de conceito para projetos de web crawler e scraper.

<p>
  <img alt="Version" src="https://img.shields.io/badge/version- 1.1.1-blue.svg?cacheSeconds=2592000" />
  <a href="https://twitter.com/MarcoManhaes" target="_blank">
    <img alt="Twitter: MarcoManhaes" src="https://img.shields.io/twitter/follow/MarcoManhaes.svg?style=social" />
  </a>
</p>

> Reposit√≥rio destinado √† prova de conceito para projetos de web crawler e scraper.

## Status

Em Desenvolvimento ‚ö†Ô∏è

## Sobre

Este projeto tem como objetivo principal realizar a prova de conceito de web crawling e scraping, no qual a aplica√ß√£o rastreia o site do Tribunal de Justi√ßa da Bah√≠a, realiza a pesquisa de processos e suas movimenta√ß√µes e, posteriormente, a raspagem dos dados do mesmo, bem como os dados das movimenta√ß√µes destes processos.
Para o processo de crawling e scraping foi utilizada a ferramenta Selenium, agregada ao projeto.

Os dados extra√≠dos s√£o estruturados em mem√≥ria pela aplica√ß√£o que consome uma API (ApiLegalScraper), que persiste estes dados estruturados em uma base Sqlite, utilizando a tecnologia Entity Framework Core.
Este banco de dados Sqlite √© gerado e autogerenciado pela aplica√ß√£o atrav√©s da tecnologia Fluent Migration, que tem como principal objetivo o versionamento do mesmo atrav√©s de scripts e mapeamentos. (A Gera√ß√£o do banco √© realizada na primeira execu√ß√£o da aplica√ß√£o).

Todo o processo de execu√ß√£o e fluxo foi registrado em LOG e salvo em arquivo cujo caminho est√° especificado abaixo neste README.

N√£o existe intera√ß√£o do usu√°rio para entrada de dados!
Ser√£o consultados no site do Tribunal de Justi√ßa da Bah√≠a, 5 (cinco) n√∫meros de processos, onde os mesmos esta√£o 'mokados' na aplica√ß√£o e seus dados s√£o buscados automaticamente sem que o usu√°rio precise inform√°-los, e ap√≥s o termino da execu√ß√£o a aplica√ß√£o √© fechada.


## Fluxo
> Fluxo simplificado de execu√ß√£o:
> (1) App inicializa --> (2) cria/atualiza base dados --> (3) realiza crawling do processo --> (4) realiza scraping do processo --> (5) consome Api Legal Scraper (Create - Processo) --> (6) persiste dados em banco --> (7) consome Aapi Legal Scraper (Get Processo/List) --> (8) realiza scraping de movimenta√ß√µes do processo --> (9) consome Aapi Legal Scraper (Create - Movimentacao) --> (10) persiste dados em banco --> (11) consome Aapi Legal Scraper (Get - Movimentacao/List) --> (12) repete os passos (3) √† (11) enquanto houver processos para pesquisa --> (13) consome Aapi Legal Scraper (Get - Processo/List) --> (14) seleciona um processo na lista e consome Aapi Legal Scraper (Get - Processo/{id}) - (15) utiliza o processo selecionado com o filtro de id e consome Aapi Legal Scraper (Update - Processo) --> (16) consome a API Legal Scraper (List - Processo/List) afim de mostrar a lista atualizada --> (17) consome a API Legal Scraper (Delete - Processo/{id}) --> (18) consome a API Legal Scraper (List - Processo/List) afim de mostrar a lista sem o registro exclu√≠do --> (19) fecha a aplica√ß√£o

## Execu√ß√£o

```sh
Baixar o projeto em uma esta√ß√£o local.

Utilizando o Visual studio:
Abra a Solution contendo o conjunto de projetos (camadas) que integram o projeto como um todo Legal Scraper, 
compile a solution e rode o projeto com F5 ou Ctrl +F5 (Debug)

Utilizando linha de comando:
No diret√≥rio raiz do projeto (onde est√° localizada a solution)execute o comando dotnet build.
Ap√≥s a compila√ß√£o sem erros, entre no riret√≥rio do projeto LegalScraper.Client execute o comando dotnet run.
```

## Como usar
> ### Pr√©-Requisitos
>   √â necess√°rio que a esta√ß√£o que executar√° o projeto contenha o Microsoft .NET Core SDK 3.1 instalado.

>   Caso deseja rodar o projeto em modo debug e analizar o c√≥digo fonte com maiores detalhes, 
>   √© necess√°rio ter o Visual studio (preferencialmente 2019) ou VS Code instalados.

> ### Local de arquivos
> Existem dois arquivos importantes gerados durante a execu√ß√£o do projeto, s√£o eles: [nome_base_dados].sqlite e [nome_log].txt

> Base de dados:  a base de dados √© gerada com o nome legal_scraper_db.sqlite no diret√≥rio:
Path.Combine(Environment.GetFolderPath(Environment.SpecialFolder.ApplicationData), "LegalScraper.Application");

> Arquivo de log: o arquivo de log √© gerado com o nome no formato {0:yyyyMMdd}_{1}.log (Ex: 20220713_LegalScraper.log) no diret√≥rio:
Path.Combine(Path.GetDirectoryName(Assembly.GetEntryAssembly().Location), "Logs");

## Tecnologias utilizadas

```sh
* Microsoft.NetCore
* Console application Core
* Asp.net Core
* Dependency Injection
* Entity Framework Core
* Fluent Migration
* Swashbuckle Swagger
* Newtonsoft.json
* Sqlite
* Selenium
* Unity
* NLog
```

## Autor

üë§ **Marco Manh√£es J√∫nior**

* Twitter: [@MarcoManhaes](https://twitter.com/MarcoManhaes)
* Github: [@MarcoManhaes](https://github.com/MarcoManhaes)
* LinkedIn: [@marco-manhaes](https://linkedin.com/in/marco-manhaes)

## Mostre seu apoio

D√™ um ‚≠êÔ∏è se esse projeto te ajudou!

***
